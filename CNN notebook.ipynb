{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "import os, shutil\n",
    "import utils\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from ML_algorithms import *\n",
    "from numpy import array\n",
    "from numpy import hstack\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"data_files/Cactus_Image/training_set\"\n",
    "test_dir = \"data_files/Cactus_Image/testing_set\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_cnn(n_neurons=32, n_layers=3, filter_size=(3, 3), activation=\"relu\", \n",
    "               input_shape =(64,64,3), max_pooling=(2,2), dense_layer=128, \n",
    "               loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=\"acc\"):\n",
    "    # NOTE: always alter the input_shape to the specific input shape off the problem.\n",
    "\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(n_neurons, filter_size, activation=activation,\n",
    "                           input_shape =input_shape))\n",
    "    model.add(layers.MaxPooling2D(max_pooling))\n",
    "    for num in range(n_layers-2):\n",
    "        model.add(layers.Conv2D(n_neurons, filter_size, activation=activation))\n",
    "        model.add(layers.MaxPooling2D(max_pooling))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(dense_layer, activation=activation))\n",
    "    model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    model.compile(loss=loss, \n",
    "                  optimizer=optimizer,\n",
    "                  metrics=[metrics])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = keras_cnn() \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(64,64),\n",
    "    batch_size=20,\n",
    "    class_mode=\"binary\")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(64, 64),\n",
    "    batch_size=20,\n",
    "    class_mode=\"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=250,\n",
    "    epochs=5,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Timeseries Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = utils.get_timeseries_dataset(cnn_or_lstm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = keras_cnn_conv1D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs=10, verbose=1, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Titanic Data \n",
    "### 2.1 conv1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = utils.get_titanic_dataset(cnn_or_lstm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras_cnn_conv1D(filters=6, input_shape=(1,36), pool_size=1,kernel_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs=100, verbose=1, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = utils.get_titanic_dataset(cnn_conv2d=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras_cnn(filter_size=(1,1), input_shape=(1, 36, 1), max_pooling=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs=10, verbose=1, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img_rows, img_cols = 1,36\n",
    "#nb_filters = 1000\n",
    "#pool_size = (1, 1)\n",
    "#kernel_size = (1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Text Data \n",
    "### 2.1 conv1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = utils.get_text_dataset(cnn_or_lstm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7464, 1, 51)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras_cnn_conv1D(filters=12, input_shape=(1,51), pool_size=1,kernel_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7464 samples, validate on 3200 samples\n",
      "Epoch 1/10\n",
      "7464/7464 [==============================] - 1s 98us/step - loss: 7.9735 - f1: 0.6518 - val_loss: 8.0943 - val_f1: 0.6529\n",
      "Epoch 2/10\n",
      "7464/7464 [==============================] - 0s 40us/step - loss: 7.9336 - f1: 0.6626 - val_loss: 8.0916 - val_f1: 0.6523\n",
      "Epoch 3/10\n",
      "7464/7464 [==============================] - 0s 38us/step - loss: 7.9975 - f1: 0.3856 - val_loss: 8.0626 - val_f1: 0.4751\n",
      "Epoch 4/10\n",
      "7464/7464 [==============================] - 0s 39us/step - loss: 8.0410 - f1: 0.5774 - val_loss: 8.1309 - val_f1: 0.5956\n",
      "Epoch 5/10\n",
      "7464/7464 [==============================] - 0s 39us/step - loss: 7.9043 - f1: 0.6195 - val_loss: 8.0375 - val_f1: 0.6373\n",
      "Epoch 6/10\n",
      "7464/7464 [==============================] - 0s 39us/step - loss: 8.0169 - f1: 0.6375 - val_loss: 8.0987 - val_f1: 0.6153\n",
      "Epoch 7/10\n",
      "7464/7464 [==============================] - 0s 39us/step - loss: 8.1179 - f1: 0.6192 - val_loss: 8.0521 - val_f1: 0.6243\n",
      "Epoch 8/10\n",
      "7464/7464 [==============================] - 0s 39us/step - loss: 7.9966 - f1: 0.6410 - val_loss: 8.1337 - val_f1: 0.6315\n",
      "Epoch 9/10\n",
      "7464/7464 [==============================] - 0s 38us/step - loss: 7.9393 - f1: 0.6469 - val_loss: 8.1671 - val_f1: 0.6354\n",
      "Epoch 10/10\n",
      "7464/7464 [==============================] - 0s 38us/step - loss: 7.9579 - f1: 0.6494 - val_loss: 8.1067 - val_f1: 0.6395\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe53c13aa58>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10, verbose=1, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7464 samples, validate on 3200 samples\n",
      "Epoch 1/100\n",
      "7464/7464 [==============================] - 2s 224us/step - loss: 7.9040 - f1: 0.5671 - val_loss: 7.9484 - val_f1: 0.5070\n",
      "Epoch 2/100\n",
      "7464/7464 [==============================] - 1s 165us/step - loss: 8.0008 - f1: 0.4345 - val_loss: 8.0458 - val_f1: 0.5772\n",
      "Epoch 3/100\n",
      "7464/7464 [==============================] - 1s 159us/step - loss: 7.9354 - f1: 0.5277 - val_loss: 7.9071 - val_f1: 0.4988\n",
      "Epoch 4/100\n",
      "7464/7464 [==============================] - 1s 159us/step - loss: 7.9296 - f1: 0.5198 - val_loss: 7.8725 - val_f1: 0.4593\n",
      "Epoch 5/100\n",
      "7464/7464 [==============================] - 1s 159us/step - loss: 7.9272 - f1: 0.4781 - val_loss: 7.9701 - val_f1: 0.5114\n",
      "Epoch 6/100\n",
      "7464/7464 [==============================] - 1s 158us/step - loss: 7.9249 - f1: 0.4724 - val_loss: 7.6782 - val_f1: 0.5432\n",
      "Epoch 7/100\n",
      "7464/7464 [==============================] - 1s 160us/step - loss: 7.9902 - f1: 0.5075 - val_loss: 7.6801 - val_f1: 0.5218\n",
      "Epoch 8/100\n",
      "7464/7464 [==============================] - 1s 159us/step - loss: 8.0039 - f1: 0.5064 - val_loss: 7.8822 - val_f1: 0.5286\n",
      "Epoch 9/100\n",
      "7464/7464 [==============================] - 1s 162us/step - loss: 8.0748 - f1: 0.4954 - val_loss: 7.7894 - val_f1: 0.4118\n",
      "Epoch 10/100\n",
      "7464/7464 [==============================] - 1s 166us/step - loss: 8.1064 - f1: 0.3022 - val_loss: 7.8251 - val_f1: 0.1050\n",
      "Epoch 11/100\n",
      "7464/7464 [==============================] - 1s 163us/step - loss: 8.2033 - f1: 0.0536 - val_loss: 7.7868 - val_f1: 0.0312\n",
      "Epoch 12/100\n",
      "7464/7464 [==============================] - 1s 164us/step - loss: 8.1827 - f1: 0.0209 - val_loss: 7.7580 - val_f1: 0.0027\n",
      "Epoch 13/100\n",
      "7464/7464 [==============================] - 1s 161us/step - loss: 8.1624 - f1: 0.0069 - val_loss: 7.7665 - val_f1: 0.0275\n",
      "Epoch 14/100\n",
      "7464/7464 [==============================] - 1s 161us/step - loss: 8.2031 - f1: 0.0804 - val_loss: 7.7409 - val_f1: 0.2005\n",
      "Epoch 15/100\n",
      "7464/7464 [==============================] - 1s 165us/step - loss: 8.1703 - f1: 0.2591 - val_loss: 7.8552 - val_f1: 0.2803\n",
      "Epoch 16/100\n",
      "7464/7464 [==============================] - 1s 163us/step - loss: 8.0880 - f1: 0.2651 - val_loss: 7.7461 - val_f1: 0.2194\n",
      "Epoch 17/100\n",
      "7464/7464 [==============================] - 1s 160us/step - loss: 8.0913 - f1: 0.2036 - val_loss: 7.8522 - val_f1: 0.1664\n",
      "Epoch 18/100\n",
      "7464/7464 [==============================] - 1s 159us/step - loss: 8.1505 - f1: 0.0846 - val_loss: 7.7497 - val_f1: 0.0319\n",
      "Epoch 19/100\n",
      "7464/7464 [==============================] - 1s 163us/step - loss: 8.1999 - f1: 0.0267 - val_loss: 7.7608 - val_f1: 0.0353\n",
      "Epoch 20/100\n",
      "7464/7464 [==============================] - 1s 162us/step - loss: 8.2013 - f1: 0.0306 - val_loss: 7.7560 - val_f1: 0.0319\n",
      "Epoch 21/100\n",
      "7464/7464 [==============================] - 1s 162us/step - loss: 8.1735 - f1: 0.0127 - val_loss: 7.7357 - val_f1: 0.0420\n",
      "Epoch 22/100\n",
      "7464/7464 [==============================] - 1s 160us/step - loss: 8.1847 - f1: 0.0390 - val_loss: 7.7730 - val_f1: 0.0477\n",
      "Epoch 23/100\n",
      "7464/7464 [==============================] - 1s 159us/step - loss: 8.1847 - f1: 0.0392 - val_loss: 7.7730 - val_f1: 0.0477\n",
      "Epoch 24/100\n",
      "7464/7464 [==============================] - 1s 163us/step - loss: 8.1847 - f1: 0.0404 - val_loss: 7.7730 - val_f1: 0.0477\n",
      "Epoch 25/100\n",
      "7464/7464 [==============================] - 1s 160us/step - loss: 8.1847 - f1: 0.0389 - val_loss: 7.7730 - val_f1: 0.0477\n",
      "Epoch 26/100\n",
      "7464/7464 [==============================] - 1s 160us/step - loss: 8.1847 - f1: 0.0392 - val_loss: 7.7730 - val_f1: 0.0477\n",
      "Epoch 27/100\n",
      "7464/7464 [==============================] - 1s 159us/step - loss: 8.1847 - f1: 0.0415 - val_loss: 7.7730 - val_f1: 0.0477\n",
      "Epoch 28/100\n",
      "7464/7464 [==============================] - 1s 176us/step - loss: 8.1847 - f1: 0.0393 - val_loss: 7.7730 - val_f1: 0.0477\n",
      "Epoch 29/100\n",
      "7464/7464 [==============================] - 1s 194us/step - loss: 8.1847 - f1: 0.0405 - val_loss: 7.7730 - val_f1: 0.0477\n",
      "Epoch 30/100\n",
      "7464/7464 [==============================] - 1s 191us/step - loss: 8.1847 - f1: 0.0393 - val_loss: 7.7730 - val_f1: 0.0477\n",
      "Epoch 31/100\n",
      "7464/7464 [==============================] - 1s 192us/step - loss: 8.1847 - f1: 0.0405 - val_loss: 7.7730 - val_f1: 0.0477\n",
      "Epoch 32/100\n",
      "7464/7464 [==============================] - 1s 198us/step - loss: 8.1847 - f1: 0.0392 - val_loss: 7.7730 - val_f1: 0.0477\n",
      "Epoch 33/100\n",
      "7464/7464 [==============================] - 2s 205us/step - loss: 8.1847 - f1: 0.0400 - val_loss: 7.7730 - val_f1: 0.0477\n",
      "Epoch 34/100\n",
      "7464/7464 [==============================] - 1s 199us/step - loss: 8.1847 - f1: 0.0395 - val_loss: 7.7730 - val_f1: 0.0477\n",
      "Epoch 35/100\n",
      "7464/7464 [==============================] - 1s 195us/step - loss: 8.1847 - f1: 0.0412 - val_loss: 7.7729 - val_f1: 0.0477\n",
      "Epoch 36/100\n",
      "7464/7464 [==============================] - 1s 193us/step - loss: 8.1847 - f1: 0.0400 - val_loss: 7.7729 - val_f1: 0.0477\n",
      "Epoch 37/100\n",
      "7464/7464 [==============================] - 1s 194us/step - loss: 8.1847 - f1: 0.0416 - val_loss: 7.7729 - val_f1: 0.0477\n",
      "Epoch 38/100\n",
      "7464/7464 [==============================] - 1s 195us/step - loss: 8.1847 - f1: 0.0399 - val_loss: 7.7729 - val_f1: 0.0477\n",
      "Epoch 39/100\n",
      "7464/7464 [==============================] - 1s 195us/step - loss: 8.1847 - f1: 0.0403 - val_loss: 7.7729 - val_f1: 0.0477\n",
      "Epoch 40/100\n",
      "7464/7464 [==============================] - 1s 195us/step - loss: 8.1847 - f1: 0.0399 - val_loss: 7.7730 - val_f1: 0.0477\n",
      "Epoch 41/100\n",
      "7464/7464 [==============================] - 1s 194us/step - loss: 8.1847 - f1: 0.0404 - val_loss: 7.7728 - val_f1: 0.0477\n",
      "Epoch 42/100\n",
      "7464/7464 [==============================] - 1s 195us/step - loss: 8.1826 - f1: 0.0398 - val_loss: 7.7605 - val_f1: 0.0445\n",
      "Epoch 43/100\n",
      "7464/7464 [==============================] - 1s 195us/step - loss: 8.1912 - f1: 0.0393 - val_loss: 7.7705 - val_f1: 0.0444\n",
      "Epoch 44/100\n",
      "7464/7464 [==============================] - 1s 196us/step - loss: 8.1912 - f1: 0.0387 - val_loss: 7.7705 - val_f1: 0.0444\n",
      "Epoch 45/100\n",
      "7464/7464 [==============================] - 1s 195us/step - loss: 8.1912 - f1: 0.0395 - val_loss: 7.7705 - val_f1: 0.0444\n",
      "Epoch 46/100\n",
      "7464/7464 [==============================] - 1s 194us/step - loss: 8.1911 - f1: 0.0393 - val_loss: 7.7705 - val_f1: 0.0444\n",
      "Epoch 47/100\n",
      "7464/7464 [==============================] - 1s 197us/step - loss: 8.1912 - f1: 0.0366 - val_loss: 7.7705 - val_f1: 0.0444\n",
      "Epoch 48/100\n",
      "7464/7464 [==============================] - 1s 194us/step - loss: 8.1912 - f1: 0.0388 - val_loss: 7.7705 - val_f1: 0.0444\n",
      "Epoch 49/100\n",
      "7464/7464 [==============================] - 1s 196us/step - loss: 8.1912 - f1: 0.0381 - val_loss: 7.7704 - val_f1: 0.0444\n",
      "Epoch 50/100\n",
      "7464/7464 [==============================] - 1s 194us/step - loss: 8.1912 - f1: 0.0385 - val_loss: 7.7705 - val_f1: 0.0444\n",
      "Epoch 51/100\n",
      "7464/7464 [==============================] - 1s 195us/step - loss: 8.1911 - f1: 0.0372 - val_loss: 7.7705 - val_f1: 0.0444\n",
      "Epoch 52/100\n",
      "7464/7464 [==============================] - 1s 169us/step - loss: 8.1912 - f1: 0.0393 - val_loss: 7.7705 - val_f1: 0.0444\n",
      "Epoch 53/100\n",
      "7464/7464 [==============================] - 1s 166us/step - loss: 8.1912 - f1: 0.0384 - val_loss: 7.7704 - val_f1: 0.0444\n",
      "Epoch 54/100\n",
      "7464/7464 [==============================] - 1s 165us/step - loss: 8.1911 - f1: 0.0387 - val_loss: 7.7704 - val_f1: 0.0444\n",
      "Epoch 55/100\n",
      "7464/7464 [==============================] - 1s 166us/step - loss: 8.1912 - f1: 0.0376 - val_loss: 7.7704 - val_f1: 0.0444\n",
      "Epoch 56/100\n",
      "7464/7464 [==============================] - 1s 170us/step - loss: 8.1912 - f1: 0.0378 - val_loss: 7.7704 - val_f1: 0.0444\n",
      "Epoch 57/100\n",
      "7464/7464 [==============================] - 1s 194us/step - loss: 8.1912 - f1: 0.0384 - val_loss: 7.7704 - val_f1: 0.0444\n",
      "Epoch 58/100\n",
      "7464/7464 [==============================] - 1s 196us/step - loss: 8.1912 - f1: 0.0393 - val_loss: 7.7704 - val_f1: 0.0444\n",
      "Epoch 59/100\n",
      "7464/7464 [==============================] - 1s 189us/step - loss: 8.1912 - f1: 0.0383 - val_loss: 7.7704 - val_f1: 0.0444\n",
      "Epoch 60/100\n",
      "7464/7464 [==============================] - 1s 200us/step - loss: 8.1339 - f1: 0.1230 - val_loss: 7.6243 - val_f1: 0.3408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "7464/7464 [==============================] - 1s 190us/step - loss: 7.9971 - f1: 0.3465 - val_loss: 7.6811 - val_f1: 0.4031\n",
      "Epoch 62/100\n",
      "7464/7464 [==============================] - 1s 189us/step - loss: 7.8965 - f1: 0.4202 - val_loss: 7.8410 - val_f1: 0.5503\n",
      "Epoch 63/100\n",
      "7464/7464 [==============================] - 1s 190us/step - loss: 7.8701 - f1: 0.5811 - val_loss: 7.8290 - val_f1: 0.5954\n",
      "Epoch 64/100\n",
      "7464/7464 [==============================] - 1s 191us/step - loss: 7.8435 - f1: 0.6008 - val_loss: 7.8351 - val_f1: 0.5914\n",
      "Epoch 65/100\n",
      "7464/7464 [==============================] - 1s 191us/step - loss: 7.9310 - f1: 0.5456 - val_loss: 7.8034 - val_f1: 0.5217\n",
      "Epoch 66/100\n",
      "7464/7464 [==============================] - 1s 191us/step - loss: 7.9655 - f1: 0.5146 - val_loss: 7.7452 - val_f1: 0.4854\n",
      "Epoch 67/100\n",
      "7464/7464 [==============================] - 1s 163us/step - loss: 8.0700 - f1: 0.4721 - val_loss: 7.7562 - val_f1: 0.4782\n",
      "Epoch 68/100\n",
      "7464/7464 [==============================] - 1s 159us/step - loss: 7.9925 - f1: 0.4451 - val_loss: 7.7397 - val_f1: 0.4144\n",
      "Epoch 69/100\n",
      "7464/7464 [==============================] - 1s 178us/step - loss: 8.0643 - f1: 0.3217 - val_loss: 7.6914 - val_f1: 0.2674\n",
      "Epoch 70/100\n",
      "7464/7464 [==============================] - 1s 187us/step - loss: 8.0998 - f1: 0.2447 - val_loss: 7.7676 - val_f1: 0.2521\n",
      "Epoch 71/100\n",
      "7464/7464 [==============================] - 1s 191us/step - loss: 8.1470 - f1: 0.2171 - val_loss: 7.7380 - val_f1: 0.1769\n",
      "Epoch 72/100\n",
      "7464/7464 [==============================] - 1s 192us/step - loss: 8.1385 - f1: 0.1676 - val_loss: 7.7871 - val_f1: 0.1606\n",
      "Epoch 73/100\n",
      "7464/7464 [==============================] - 1s 178us/step - loss: 8.1304 - f1: 0.1491 - val_loss: 7.7457 - val_f1: 0.1112\n",
      "Epoch 74/100\n",
      "7464/7464 [==============================] - 1s 178us/step - loss: 8.1662 - f1: 0.1136 - val_loss: 7.7757 - val_f1: 0.1327\n",
      "Epoch 75/100\n",
      "7464/7464 [==============================] - 1s 188us/step - loss: 8.1986 - f1: 0.1148 - val_loss: 7.7773 - val_f1: 0.1051\n",
      "Epoch 76/100\n",
      "7464/7464 [==============================] - 1s 191us/step - loss: 8.1598 - f1: 0.0660 - val_loss: 7.7590 - val_f1: 0.0764\n",
      "Epoch 77/100\n",
      "7464/7464 [==============================] - 1s 175us/step - loss: 8.1641 - f1: 0.0645 - val_loss: 7.7589 - val_f1: 0.0764\n",
      "Epoch 78/100\n",
      "7464/7464 [==============================] - 1s 182us/step - loss: 8.1641 - f1: 0.0654 - val_loss: 7.7589 - val_f1: 0.0764\n",
      "Epoch 79/100\n",
      "7464/7464 [==============================] - 1s 183us/step - loss: 8.1641 - f1: 0.0648 - val_loss: 7.7589 - val_f1: 0.0764\n",
      "Epoch 80/100\n",
      "7464/7464 [==============================] - 1s 186us/step - loss: 8.1641 - f1: 0.0645 - val_loss: 7.7589 - val_f1: 0.0764\n",
      "Epoch 81/100\n",
      "7464/7464 [==============================] - 1s 192us/step - loss: 8.1641 - f1: 0.0639 - val_loss: 7.7589 - val_f1: 0.0764\n",
      "Epoch 82/100\n",
      "7464/7464 [==============================] - 1s 191us/step - loss: 8.1641 - f1: 0.0674 - val_loss: 7.7589 - val_f1: 0.0764\n",
      "Epoch 83/100\n",
      "7464/7464 [==============================] - 1s 191us/step - loss: 8.1641 - f1: 0.0652 - val_loss: 7.7589 - val_f1: 0.0764\n",
      "Epoch 84/100\n",
      "7464/7464 [==============================] - 1s 189us/step - loss: 8.1641 - f1: 0.0648 - val_loss: 7.7589 - val_f1: 0.0764\n",
      "Epoch 85/100\n",
      "7464/7464 [==============================] - 1s 190us/step - loss: 8.1641 - f1: 0.0654 - val_loss: 7.7589 - val_f1: 0.0764\n",
      "Epoch 86/100\n",
      "7464/7464 [==============================] - 1s 190us/step - loss: 8.1641 - f1: 0.0676 - val_loss: 7.7589 - val_f1: 0.0764\n",
      "Epoch 87/100\n",
      "7464/7464 [==============================] - 1s 190us/step - loss: 8.1641 - f1: 0.0660 - val_loss: 7.7589 - val_f1: 0.0764\n",
      "Epoch 88/100\n",
      "7464/7464 [==============================] - 1s 192us/step - loss: 8.1641 - f1: 0.0651 - val_loss: 7.7589 - val_f1: 0.0764\n",
      "Epoch 89/100\n",
      "7464/7464 [==============================] - 1s 191us/step - loss: 8.1641 - f1: 0.0648 - val_loss: 7.7589 - val_f1: 0.0764\n",
      "Epoch 90/100\n",
      "7464/7464 [==============================] - 1s 190us/step - loss: 8.1641 - f1: 0.0661 - val_loss: 7.7589 - val_f1: 0.0764\n",
      "Epoch 91/100\n",
      "7464/7464 [==============================] - 1s 191us/step - loss: 8.1641 - f1: 0.0655 - val_loss: 7.7589 - val_f1: 0.0764\n",
      "Epoch 92/100\n",
      "7464/7464 [==============================] - 1s 191us/step - loss: 8.1641 - f1: 0.0644 - val_loss: 7.7589 - val_f1: 0.0764\n",
      "Epoch 93/100\n",
      "7464/7464 [==============================] - 1s 192us/step - loss: 8.1641 - f1: 0.0665 - val_loss: 7.7589 - val_f1: 0.0764\n",
      "Epoch 94/100\n",
      "7464/7464 [==============================] - 1s 190us/step - loss: 8.1641 - f1: 0.0661 - val_loss: 7.7589 - val_f1: 0.0764\n",
      "Epoch 95/100\n",
      "7464/7464 [==============================] - 1s 192us/step - loss: 8.1641 - f1: 0.0653 - val_loss: 7.7589 - val_f1: 0.0764\n",
      "Epoch 96/100\n",
      "7464/7464 [==============================] - 1s 191us/step - loss: 8.1641 - f1: 0.0646 - val_loss: 7.7589 - val_f1: 0.0764\n",
      "Epoch 97/100\n",
      "7464/7464 [==============================] - 1s 178us/step - loss: 8.1641 - f1: 0.0658 - val_loss: 7.7589 - val_f1: 0.0764\n",
      "Epoch 98/100\n",
      "7464/7464 [==============================] - 1s 156us/step - loss: 8.1641 - f1: 0.0664 - val_loss: 7.7589 - val_f1: 0.0764\n",
      "Epoch 99/100\n",
      "7464/7464 [==============================] - 1s 160us/step - loss: 8.1641 - f1: 0.0661 - val_loss: 7.7589 - val_f1: 0.0764\n",
      "Epoch 100/100\n",
      "7464/7464 [==============================] - 1s 158us/step - loss: 8.1641 - f1: 0.0629 - val_loss: 7.7589 - val_f1: 0.0764\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe57a002240>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = utils.get_text_dataset(cnn_conv2d=True)\n",
    "\n",
    "model = keras_cnn(filter_size=(1,1), input_shape=(1, 51, 1), max_pooling=(1,1))\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100, verbose=1, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Activation, Dropout, Convolution2D, MaxPooling2D, Flatten\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(nb_filters, filter_size=(1,1),\n",
    "                        border_mode='valid',\n",
    "                        input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=pool_size))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.compile(loss='mean_squared_error', optimizer='Nadam', metrics=['binary_accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train_onehot, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Activation, Dropout, Convolution2D, MaxPooling2D, Flatten\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, filter_size=(1,1), activation=\"relu\", input_shape=input_shape))\n",
    "model.add(layers.MaxPooling2D(pool_size))\n",
    "model.add(layers.Conv2D(32, filter_size=(1,1), activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D(pool_size))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(dense_layer, activation=activation))\n",
    "model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='Nadam', metrics=['binary_accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train_onehot, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.as_matrix().reshape((len(X_train), 15))\n",
    "y_train = y_train.as_matrix().reshape((len(y_train), 1))\n",
    "X_test = X_test.as_matrix().reshape((len(X_test), 15))\n",
    "y_test = y_test.as_matrix().reshape((len(y_test), 1))\n",
    "\n",
    "train_dataset=hstack((X_train,y_train))\n",
    "test_dataset=hstack((X_test,y_test))\n",
    "\n",
    "def split_sequences(sequences, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the dataset\n",
    "        if end_ix > len(sequences):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1, -1]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)\n",
    "\n",
    "X_train, y_train = split_sequences(train_dataset, 3)\n",
    "X_test, y_test = split_sequences(test_dataset, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_cnn_conv1D(filters=64, n_layers=2, kernel_size=2, activation=\"relu\", \n",
    "               input_shape =(3,15), pool_size=2, dense_layer=50, \n",
    "               loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=\"acc\"):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=filters, kernel_size=kernel_size, activation=activation, input_shape=input_shape))\n",
    "    model.add(MaxPooling1D(pool_size=pool_size))\n",
    "    for num in range(n_layers-2):\n",
    "        model.add(Conv1D(filters=filters, kernel_size=kernen_size, activation=activation, input_shape=input_shape))\n",
    "        model.add(MaxPooling1D(pool_size=pool_size))    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(dense_layer, activation=activation))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=loss,\n",
    "                  metrics=[metrics])\n",
    "    \n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
